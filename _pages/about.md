---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Zhang Jiawei currently works for [SenseTime](https://www.sensetime.com/en). He obtained a PhD degree from [CS](https://www.cs.cityu.edu.hk/) of City University of Hong Kong supervised by [Yang Qingxiong](https://scholar.google.com/citations?user=4WirkacAAAAJ&hl=zh-CN) in 2018, a master degree from Institute of Acoustics, Chinese Academy of Sciences ([IACAS](http://www.ioa.ac.cn/)) in 2014, and a bachelor degree from [EEIS](https://eeis.ustc.edu.cn/main.htm) of University of Science and Technology of China (USTC) in 2011. He visited UCLA in 2013 and UC Merced supervised by [Yang Ming-Hsuan](https://scholar.google.com/citations?user=p9-ohHsAAAAJ&hl=zh-CN) in 2017 respectively. He also had an internship in SenseTime in 2017 and [WeRide](https://www.weride.ai/) in 2018. He is currently interested in applying low-level vision technologies to mobile cameras and has developed various products used in OPPO, VIVO, Xiaomi, Transsion and Honor for image demosaicing, denoising, super-resolution and HDR.

Selected Publications
======
* DiT4SR: Taming Diffusion Transformer for Real-World Image Super-Resolution. [arxiv](https://arxiv.org/pdf/2503.23580?) and [code](https://adam-duan.github.io/projects/dit4sr/)
* DeblurDiff: Real-World Image Deblurring with Generative Diffusion Models. [arxiv](https://arxiv.org/pdf/2502.03810) and [code](https://github.com/kkkls/DeblurDiff)
* A Diffusion-Based Framework for Occluded Object Movement. AAAI 2025. [paper](https://ojs.aaai.org/index.php/AAAI/article/view/32287/34442) and [arxiv](https://arxiv.org/pdf/2504.01873)
* DiffRetouch: Using Diffusion to Retouch on the Shoulder of Experts. AAAI 2025. [paper](https://ojs.aaai.org/index.php/AAAI/article/view/32288/34443) and [arxiv](https://arxiv.org/pdf/2407.03757)
* Analysis and Benchmarking of Extending Blind Face Image Restoration to Videos. TIP 2024. [paper](https://ieeexplore.ieee.org/abstract/document/10693312/), [arxiv](https://arxiv.org/abs/2410.11828) and [code](https://wzhouxiff.github.io/projects/FIR2FVR/FIR2FVR)
* Deep Richardsonâ€“Lucy deconvolution for low-light image deblurring. IJCV 2024. [paper](https://link.springer.com/article/10.1007/s11263-023-01877-9) and [arxiv](https://arxiv.org/pdf/2308.05543)
* Diffusion-based Blind Text Image Super-Resolution. CVPR 2024. [paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Diffusion-based_Blind_Text_Image_Super-Resolution_CVPR_2024_paper.pdf) and [code](https://github.com/YuzheZhang-1999/DiffTSR)
* RestoreFormer++: Towards Real-World Blind Face Restoration From Undegraded Key-Value Pairs. TPAMI 2023. [paper](https://ieeexplore.ieee.org/abstract/document/10251989), [arxiv](https://arxiv.org/pdf/2308.07228) and [code](https://github.com/wzhouxiff/RestoreFormerPlusPlus)
* Restoreformer: High-quality blind face restoration from undegraded key-value pairs. CVPR 2022. [paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_RestoreFormer_High-Quality_Blind_Face_Restoration_From_Undegraded_Key-Value_Pairs_CVPR_2022_paper.pdf), [code](https://github.com/wzhouxiff/RestoreFormer) and [huggingface](https://huggingface.co/spaces/wzhouxiff/RestoreFormerPlusPlus)
* Deep Dynamic Scene Deblurring from Optical Flow. TCSVT 2021. [paper](https://ieeexplore.ieee.org/document/9443198), [arxiv](https://arxiv.org/pdf/2301.07329)  and [code](https://github.com/zhjwustc/cvpr18_rnn_deblur_matcaffe)
* Blind deblurring for saturated images. CVPR 2021. [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Blind_Deblurring_for_Saturated_Images_CVPR_2021_paper.pdf) and [code](https://drive.google.com/file/d/1Yyyub_ylDY5IXfE57DvsdecG7HlkSFBS/view)
* Learning a non-blind deblurring network for night blurry images. CVPR 2021. [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Learning_a_Non-Blind_Deblurring_Network_for_Night_Blurry_Images_CVPR_2021_paper.pdf), [code](https://drive.google.com/file/d/1Dxnr3vHLqA2mpDelSWxJxv2Ek84NoTwH/view) and [dataset](https://drive.google.com/file/d/1C7J9rn2xbeJ4-Aom4KEQJdpFyBd2M4Zv/view)
* Cross-scale internal graph neural network for image super-resolution. NIPS 2020. [paper](https://proceedings.neurips.cc/paper/2020/file/23ad3e314e2a2b43b4c720507cec0723-Paper.pdf) and [code](https://github.com/sczhou/IGNN)
* Learning a reinforced agent for flexible exposure bracketing selection. CVPR 2020. [paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Learning_a_Reinforced_Agent_for_Flexible_Exposure_Bracketing_Selection_CVPR_2020_paper.pdf) and [code](https://github.com/wzhouxiff/EBSNetMEFNet)
* Spatio-temporal filter adaptive network for video deblurring. ICCV 2019. [paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhou_Spatio-Temporal_Filter_Adaptive_Network_for_Video_Deblurring_ICCV_2019_paper.pdf) and [code](https://shangchenzhou.com/projects/stfan/)
* Davanet: Stereo deblurring with view aggregation. CVPR 2019 <font color="#FF000" >Spotlight</font>. [paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhou_DAVANet_Stereo_Deblurring_With_View_Aggregation_CVPR_2019_paper.pdf), [code](https://github.com/sczhou/DAVANet) and [dataset](https://shangchenzhou.com/projects/stereoblur/)
* Dynamic Scene Deblurring using Spatially Variant Recurrent Neural Networks. CVPR 2018 <font color="#FF000" >Spotlight</font>. [paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Dynamic_Scene_Deblurring_CVPR_2018_paper.pdf) and [code](https://github.com/zhjwustc/cvpr18_rnn_deblur_matcaffe)
* Learning Fully Convolutional Networks for Iterative Non-blind Deconvolution. CVPR 2017. [paper](https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Learning_Fully_Convolutional_CVPR_2017_paper.pdf) and [testing code](https://github.com/zhjwustc/cvpr17_iter_deblur_testing_matconvnet)/[training and testing code](https://github.com/zhjwustc/cvpr17_iter_deblur_matcaffe)
* 3D Hand Pose Tracking and Estimation Using a Stereo Camera. ICIP 2017 <font color="#FF000" >Oral</font>.  [paper](https://ieeexplore.ieee.org/document/8296428), [arxiv](https://arxiv.org/pdf/1610.07214), Dataset download from [onedrive](https://portland-my.sharepoint.com/personal/jiawzhang8-c_my_cityu_edu_hk/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fjiawzhang8%2Dc%5Fmy%5Fcityu%5Fedu%5Fhk%2FDocuments%2Fstereo%20hand%20pose%20dataset&ga=1)  or [baidu pan](https://pan.baidu.com/s/1Aq27-Ntyz_fqyiT-T9af0w?pwd=1234)(code: 1234) and [github](https://github.com/zhjwustc/icip17_stereo_hand_pose_dataset)



